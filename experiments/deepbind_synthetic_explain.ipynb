{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aba14cc-55f8-4775-848e-5c6e4849443f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np, os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "\n",
    "from src.utils.synthetic_seqdata import download_data, load_data, sequence_string_to_one_hot\n",
    "from src.models import DeepBindCNN\n",
    "from src.trainer import Trainer\n",
    "from src.utils.datasets import DNASequenceDataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from src.utils import metrics\n",
    "from src.explain import Explainer\n",
    "\n",
    "import matplotlib as mpl \n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1305f2-450c-415d-b48a-dc20c8e25503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000,\n",
       " {'train': array([1., 1., 0., ..., 1., 0., 1.], dtype=float32),\n",
       "  'valid': array([0., 1., 1., ..., 0., 0., 1.], dtype=float32),\n",
       "  'test': array([0., 1., 0., ..., 1., 1., 1.], dtype=float32)},\n",
       " 14000,\n",
       " 2000,\n",
       " 4000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data \n",
    "savedir = \"./data\"\n",
    "# _=download_data(savedir)\n",
    "Xs, Ys = load_data(savedir=savedir)\n",
    "len(Xs['train']), Ys, len(Ys['train']), len(Ys['valid']), len(Ys['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217bc5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c93654",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"deepbind\",\n",
    "    \"dataset\": \"synthetic data\",\n",
    "    \"epochs\": 35,\n",
    "    \"patience\": 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30412a0c-b264-499b-9b59-c0e95f87496d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepBindCNN(\n",
      "  (conv1): Conv1d(4, 16, kernel_size=(3,), stride=(1,))\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# set up datasets\n",
    "datasets = {}\n",
    "for k in Xs:\n",
    "    datasets[k] = DNASequenceDataset(sequences=Xs[k], labels=Ys[k], alphabet=\"ACGT\")\n",
    "\n",
    "# set up dataloaders \n",
    "loaders = {}\n",
    "for k, dataset in datasets.items():\n",
    "    if k == 'train':\n",
    "        loaders[k] = torch.utils.data.DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    else:\n",
    "        loaders[k] = torch.utils.data.DataLoader(dataset, batch_size=config['batch_size'])\n",
    "    \n",
    "# set up the model, lossfn, optimizer, trainer \n",
    "model = DeepBindCNN(input_size=4, output_size=1, kernel_size=3)\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "159df4dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m sample_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39mlen\u001b[39m(datasets[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m      5\u001b[0m input_sequence, target_label \u001b[39m=\u001b[39m datasets[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m][sample_index]\n\u001b[0;32m----> 7\u001b[0m saliency_scores \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39msaliency_map(input_sequence)\n\u001b[1;32m      8\u001b[0m saliency_scores\n",
      "File \u001b[0;32m~/Documents/fall_co-op_2023/experiments/../src/explain/explainer.py:28\u001b[0m, in \u001b[0;36mExplainer.saliency_map\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mArguments\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m---------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mscores <torch.tensor> - The saliency scores for each feature in each sample; same shape as input. \u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m x\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \n\u001b[0;32m---> 28\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)  \u001b[39m# shape (batch size, num classes)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m y \u001b[39m=\u001b[39m y[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_idx]  \u001b[39m# shape (batch size,)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(y, x, grad_outputs\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mones_like(x))[\u001b[39m0\u001b[39m] \u001b[39m# shape same as x \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/fall_co-op_2023/experiments/../src/models/deepbind_cnn.py:17\u001b[0m, in \u001b[0;36mDeepBindCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x))\n\u001b[1;32m     16\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(x)\n\u001b[0;32m---> 17\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(x, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# Global Average Pooling\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# x = self.dropout(x)  # dropout after pooling\u001b[39;00m\n\u001b[1;32m     19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "explainer = Explainer(model, 0)\n",
    "\n",
    "# Select a random sample from the test dataset\n",
    "sample_index = np.random.randint(len(datasets['test']))\n",
    "input_sequence, target_label = datasets['test'][sample_index]\n",
    "\n",
    "saliency_scores = explainer.saliency_map(input_sequence)\n",
    "saliency_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5428d086",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Mismatch in shape: grad_output[0] has a shape of torch.Size([32, 4, 200]) and output[0] has a shape of torch.Size([32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Step 4: Calculate the saliency map for the batch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m saliency_scores \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39msaliency_map(inputs)\n",
      "File \u001b[0;32m~/Documents/fall_co-op_2023/experiments/../src/explain/explainer.py:30\u001b[0m, in \u001b[0;36mExplainer.saliency_map\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)  \u001b[39m# shape (batch size, num classes)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m y \u001b[39m=\u001b[39m y[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_idx]  \u001b[39m# shape (batch size,)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(y, x, grad_outputs\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mones_like(x))[\u001b[39m0\u001b[39m] \u001b[39m# shape same as x \u001b[39;00m\n\u001b[1;32m     31\u001b[0m scores \u001b[39m=\u001b[39m x\u001b[39m*\u001b[39mgrad \n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:285\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    280\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39monly_inputs argument is deprecated and is ignored now \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m(defaults to True). To accumulate gradient for other \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mparts of the graph, please use torch.autograd.backward.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m grad_outputs_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_outputs, \u001b[39mlen\u001b[39m(t_outputs))\n\u001b[0;32m--> 285\u001b[0m grad_outputs_ \u001b[39m=\u001b[39m _make_grads(t_outputs, grad_outputs_, is_grads_batched\u001b[39m=\u001b[39mis_grads_batched)\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:68\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf `is_grads_batched=True`, we interpret the first \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mdimension of each grad_output as the batch dimension. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mThe sizes of the remaining dimensions are expected to match \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mIf you only want some tensors in `grad_output` to be considered \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mbatched, consider using vmap.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMismatch in shape: grad_output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(grads\u001b[39m.\u001b[39mindex(grad)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a shape of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(grad_shape) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m and output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(outputs\u001b[39m.\u001b[39mindex(out)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a shape of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out_shape) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex \u001b[39m!=\u001b[39m grad\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex:\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFor complex Tensors, both grad_output and output\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m are required to have the same dtype.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m Mismatch in dtype: grad_output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m                        \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(outputs\u001b[39m.\u001b[39mindex(out)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a dtype of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m                        \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out\u001b[39m.\u001b[39mdtype) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Mismatch in shape: grad_output[0] has a shape of torch.Size([32, 4, 200]) and output[0] has a shape of torch.Size([32])."
     ]
    }
   ],
   "source": [
    "for batch in loaders['test']:  # Assuming you want to calculate for the 'train' dataset\n",
    "    inputs, labels = batch\n",
    "    # Step 3: Move the input and labels to the device (GPU or CPU)\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Step 4: Calculate the saliency map for the batch\n",
    "    saliency_scores = explainer.saliency_map(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80fb9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
